import streamlit as st
import pandas as pd
import numpy as np
import pickle
from pathlib import Path
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
import streamlit.components.v1 as components

# -------------------- ì „ì—­: í˜ì´ì§€/ë²ˆì—­ ì°¨ë‹¨ --------------------
st.set_page_config(page_title="ì—¬í–‰ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ", layout="wide")

# ìë™ ë²ˆì—­/êµì • ì°¨ë‹¨
components.html("""
<script>
try {
  document.documentElement.setAttribute('translate','no');
  document.documentElement.classList.add('notranslate');
  document.body && document.body.setAttribute('translate','no');
  const meta = document.createElement('meta');
  meta.setAttribute('name','google');
  meta.setAttribute('value','notranslate');
  document.head.appendChild(meta);
} catch (e) {}
</script>
""", height=0)

def T(md: str):
    st.markdown(f'<div translate="no" class="notranslate" lang="ko">{md}</div>', unsafe_allow_html=True)

# -------------------- ìŠ¤í‚¤ë§ˆ/ìƒìˆ˜ --------------------
NUMERIC_FEATURES = [
    "AGE_GRP",
    "TRAVEL_STYL_1_GROUP","TRAVEL_STYL_2_GROUP","TRAVEL_STYL_3_GROUP",
    "TRAVEL_STYL_4_GROUP","TRAVEL_STYL_5_GROUP","TRAVEL_STYL_6_GROUP",
    "TRAVEL_STYL_7_GROUP","TRAVEL_STYL_8_GROUP",
]
ACCOMPANY_CATS = [
    "ë‚˜í™€ë¡œ ì—¬í–‰","ìë…€ ë™ë°˜ ì—¬í–‰","2ì¸ ê°€ì¡± ì—¬í–‰","2ì¸ ì—¬í–‰(ê°€ì¡± ì™¸)",
    "ë¶€ëª¨ ë™ë°˜ ì—¬í–‰","3ì¸ ì´ìƒ ì—¬í–‰(ê°€ì¡± ì™¸)","3ëŒ€ ë™ë°˜ ì—¬í–‰(ì¹œì²™ í¬í•¨)","3ì¸ ì´ìƒ ê°€ì¡± ì—¬í–‰(ì¹œì²™ í¬í•¨)",
]
RESIDENCE_CATS = [11,28,41,48,45,44,50,27,26,30,36,29,31,47,46,43,42]
CATEGORICAL_FEATURES = ["TRAVEL_STATUS_ACCOMPANY", "RESIDENCE_SGG_CD"]
ALL_FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES

# ê°€ìš´ë°(2) ë¼ë²¨ì€ í™”ë©´ì— ìˆ¨ê¹€(ê³µë°±) â€” ê¸°ëŠ¥ì  ì„ íƒì€ ê°€ëŠ¥
STYLE_LABELS = {
    "TRAVEL_STYL_1_GROUP": ("ìì—° (1)", " ", "ë„ì‹œ (3)"),
    "TRAVEL_STYL_2_GROUP": ("ìˆ™ë°• (1)", " ", "ë‹¹ì¼ (3)"),
    "TRAVEL_STYL_3_GROUP": ("ìƒˆë¡œìš´ ì§€ì—­ (1)", " ", "ìµìˆ™í•œ ì§€ì—­ (3)"),
    "TRAVEL_STYL_4_GROUP": ("í¸í•˜ê³  ë¹„ì‹¼ ìˆ™ì†Œ (1)", " ", "ì €ë ´í•œ ìˆ™ì†Œ (3)"),
    "TRAVEL_STYL_5_GROUP": ("íœ´ì–‘/íœ´ì‹ (1)", " ", "ì•¡í‹°ë¹„í‹° (3)"),
    "TRAVEL_STYL_6_GROUP": ("ìˆ¨ì€ ëª…ì†Œ (1)", " ", "ìœ ëª… ëª…ì†Œ (3)"),
    "TRAVEL_STYL_7_GROUP": ("ê³„íš ì—¬í–‰ (1)", " ", "ì¦‰í¥ ì—¬í–‰ (3)"),
    "TRAVEL_STYL_8_GROUP": ("ì‚¬ì§„ ì´¬ì˜ ì„ í˜¸ (1)", " ", "ì‚¬ì§„ ì´¬ì˜ ë¹„ì„ í˜¸ (3)"),
}

CLUSTER_DESC = {
    0: "ë‹¹ì‹ ì€ ìì—° ì†ì—ì„œ ì—¬ìœ ë¡­ê²Œ ì‰¬ëŠ” ì—¬í–‰ì„ ì„ í˜¸í•˜ëŠ” ì—¬í–‰ìêµ°ìš”!!",
    1: "ë‹¹ì‹ ì€ ê°€ì¡±ì„ ì¢‹ì•„í•˜ë©° ë™ë°˜ ì—¬í–‰ì„ ì„ í˜¸í•˜ëŠ” ì—¬í–‰ìêµ°ìš”!!",
    2: "ë‹¹ì‹ ì€ ì²´í—˜ì„ ì¤‘ì‹œí•˜ë©° ê±°ì˜ ëª¨ë“  í™œë™ì„ ì¦ê¸°ëŠ” ì¹œêµ¬Â·ì—°ì¸ ë™ë°˜ì„ ì„ í˜¸í•˜ëŠ” ë§ŒëŠ¥ ì•¡í‹°ë¹„í‹° ì—¬í–‰ìêµ°ìš”ğŸ§—â€â™€ï¸",
    3: "ë‹¹ì‹ ì€ ìŒì‹ê³¼ ìì—°ì— ì§‘ì¤‘í•˜ë©° ì¹œêµ¬Â·ì—°ì¸ ë˜ëŠ” í˜¼ì ì—¬í–‰ì„ ì„ í˜¸í•˜ëŠ” ê°€ì„±ë¹„ ë¯¸ì‹Â·íƒí—˜ ì—¬í–‰ìêµ°ìš” ğŸœ",
}

# -------------------- ì „ì²˜ë¦¬/ëª¨ë¸ --------------------
def build_preprocessor():
    num_tf = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
    ])
    cat_tf = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(
            categories=[ACCOMPANY_CATS, RESIDENCE_CATS],
            handle_unknown="ignore",
            sparse_output=False # sparse_output=Falseë¡œ ë³€ê²½
        )),
    ])
    return ColumnTransformer([
        ("num", num_tf, NUMERIC_FEATURES),
        ("cat", cat_tf, CATEGORICAL_FEATURES),
    ])

def build_kmeans():
    return KMeans(n_clusters=4, init="k-means++", random_state=42, n_init=10)

@st.cache_resource
def load_resources():
    pre_pkl = Path("preprocessor_final_with_residence.pkl")
    km_pkl  = Path("kmeans_model_final_with_residence.pkl")
    csv_fp  = Path("final.csv")

    if not csv_fp.exists():
        T("**final.csv** íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    df = pd.read_csv(csv_fp, low_memory=False)
    for c in NUMERIC_FEATURES:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df["TRAVEL_STATUS_ACCOMPANY"] = df["TRAVEL_STATUS_ACCOMPANY"].astype("string")
    df["RESIDENCE_SGG_CD"] = pd.to_numeric(df["RESIDENCE_SGG_CD"], errors="coerce")

    pre = None
    km = None

    try:
        with open(pre_pkl, "rb") as f: pre = pickle.load(f)
        with open(km_pkl, "rb") as f: km = pickle.load(f)
        T("âœ… ì €ì¥ëœ ì „ì²˜ë¦¬ê¸°/ëª¨ë¸ **ë¡œë“œ ì™„ë£Œ**")
    except (FileNotFoundError, AttributeError): # AttributeError ì¶”ê°€
        T("âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ â†’ **ì¦‰ì„ í•™ìŠµ** ì§„í–‰")
        pre = build_preprocessor()
        km  = build_kmeans()
        X = pre.fit_transform(df[ALL_FEATURES])
        km.fit(X)
        # í•„ìš” ì‹œ ì €ì¥
        # with open(pre_pkl, "wb") as f: pickle.dump(pre, f)
        # with open(km_pkl, "wb") as f: pickle.dump(km, f)

    # êµ°ì§‘ ë¼ë²¨
    X_all = pre.transform(df[ALL_FEATURES])
    df = df.copy()
    df["cluster"] = km.predict(X_all)

    # ì¶”ì²œ í”„ë¡œí•„(TF-IDF)
    stopwords = [
        "ì œì£¼ êµ­ì œê³µí•­","ê¹€í¬êµ­ì œê³µí•­ êµ­ë‚´ì„ ","ì‚¬ë¬´ì‹¤","ì œì£¼ë™ë¬¸ì‹œì¥",
        "ì„œê·€í¬ ë§¤ì¼ ì˜¬ë ˆì‹œì¥","ì„œìš¸ì—­","ë³¸ì ","ìŠ¤íƒ€ë²…ìŠ¤","CU","GS25",
        "í•¨ë•í•´ìˆ˜ìš•ì¥","í˜‘ì¬í•´ìˆ˜ìš•ì¥","ì²­ì£¼êµ­ì œê³µí•­","ê¹€í¬ êµ­ì œê³µí•­ êµ­ë‚´ì„ ",
        "ì„±ì‚°ì¼ì¶œë´‰","ì˜¤ì„¤ë¡ í‹° ë®¤ì§€ì—„","ì„±ì‹¬ë‹¹ ë³¸ì ","ë¶€ì‚°ì—­","ëŒ€ì „ì—­","ê´‘ì£¼ê³µí•­",
        "ì„œìš¸ê³ ì†ë²„ìŠ¤í„°ë¯¸ë„","ë™ëŒ€êµ¬ì—­","ì¸ì²œêµ­ì œê³µí•­","ê´‘ëª…ì—­","ìš¸ì‚°ì—­","ê²½ë¶€",
    ]
    if "VISIT_AREA_NM" in df.columns:
        filt = ~df["VISIT_AREA_NM"].isin(stopwords)
        tmp = df.loc[filt, ["cluster","VISIT_AREA_NM"]].dropna()
        tmp["VISIT_AREA_NM_CLEAN"] = tmp["VISIT_AREA_NM"].astype(str).str.replace(" ", "_", regex=False)
        k = km.n_clusters
        grouped = tmp.groupby("cluster")["VISIT_AREA_NM_CLEAN"].apply(lambda s: " ".join(s)).reindex(range(k), fill_value="")
        corpus = grouped.tolist()

        vec = TfidfVectorizer(min_df=2)  # í•„ìš”ì‹œ 1ë¡œ ë‚®ì¶”ê¸°
        tf = vec.fit_transform(corpus)
        vocab = np.array(vec.get_feature_names_out())

        rec_profile = {}
        for i in range(tf.shape[0]):
            row = tf[i].toarray()[0]
            if row.sum() == 0:
                rec_profile[i] = ["(ë°ì´í„° ë¶€ì¡±)"]
            else:
                idx = row.argsort()[-5:][::-1]
                rec_profile[i] = [vocab[j].replace("_"," ") for j in idx]
    else:
        rec_profile = {i:["(VISIT_AREA_NM ì—†ìŒ)"] for i in range(km.n_clusters)}

    return pre, km, rec_profile

preprocessor, kmeans, recommendation_profile = load_resources()

# -------------------- ìŠ¤íƒ€ì¼ ìŠ¬ë¼ì´ë”(2 ìˆ¨ê¹€ í‘œì‹œ) --------------------
def tri_slider_hidden_mid(key: str, left_label: str, right_label: str, default=2) -> int:
    # ê°€ìš´ë° ë¼ë²¨ì€ í™”ë©´ì— ì¶œë ¥í•˜ì§€ ì•ŠìŒ(ê³µë°±)
    T(f"{left_label} Â â†â†’ Â {right_label}")
    val = st.slider(" ", 1, 3, default, step=1, key=key, label_visibility="collapsed")
    # ì„ íƒ í‘œì‹œ: 1/3ì€ êµ¬ì²´ ë¼ë²¨, 2ëŠ” 'ì¤‘ë¦½ (2)'ë§Œ ê°„ë‹¨íˆ í‘œê¸°
    if val == 1:
        T(f"ì„ íƒ: {left_label}")
    elif val == 3:
        T(f"ì„ íƒ: {right_label}")
    else:
        T("ì„ íƒ: ì¤‘ë¦½ (2)")
    return val

# -------------------- ì…ë ¥ í¼ --------------------
with st.form("user_form"):
    T("## 1. ê¸°ë³¸ ì •ë³´")

    T("ì—°ë ¹ëŒ€ (10~80)")
    age_grp = st.slider(" ", 10, 80, 30, step=10, label_visibility="collapsed")

    T("ê´€ì‹¬ ì§€ì—­")
    residence_map = {
        'ì„œìš¸íŠ¹ë³„ì‹œ': 11, 'ì¸ì²œê´‘ì—­ì‹œ': 28, 'ê²½ê¸°ë„': 41, 'ê°•ì›ë„': 42, 'ì¶©ì²­ë¶ë„': 43,
        'ì¶©ì²­ë‚¨ë„': 44, 'ì „ë¼ë¶ë„': 45, 'ì „ë¼ë‚¨ë„': 46, 'ê²½ìƒë¶ë„': 47, 'ê²½ìƒë‚¨ë„': 48,
        'ëŒ€ì „ê´‘ì—­ì‹œ': 30, 'ê´‘ì£¼ê´‘ì—­ì‹œ': 29, 'ëŒ€êµ¬ê´‘ì—­ì‹œ': 27, 'ë¶€ì‚°ê´‘ì—­ì‹œ': 26, 'ìš¸ì‚°ê´‘ì—­ì‹œ': 31,
        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': 36, 'ì œì£¼íŠ¹ë³„ìì¹˜ë„': 50
    }
    res_name = st.selectbox(" ", list(residence_map.keys()), label_visibility="collapsed")
    res_code = residence_map[res_name]

    T("ë™ë°˜ í˜•íƒœ")
    accompany = st.selectbox(" Â ", ACCOMPANY_CATS, label_visibility="collapsed")

    T("## 2. ì—¬í–‰ ìŠ¤íƒ€ì¼ (ê°€ìš´ë° ê°’ì€ ê¸°ëŠ¥ë§Œ, í‘œì‹œëŠ” ìµœì†Œí™”)")
    styles = {}
    for key, (left, _, right) in STYLE_LABELS.items():
        styles[key] = tri_slider_hidden_mid(key, left, right, default=2)

    submitted = st.form_submit_button("ì¶”ì²œë°›ê¸°")

# -------------------- ì˜ˆì¸¡/ì¶œë ¥ --------------------
def predict_cluster(pre, km, inp: dict):
    df_new = pd.DataFrame([inp], columns=ALL_FEATURES)
    for c in NUMERIC_FEATURES:
        df_new[c] = pd.to_numeric(df_new[c], errors="coerce")
    df_new["TRAVEL_STATUS_ACCOMPANY"] = df_new["TRAVEL_STATUS_ACCOMPANY"].astype("string")
    df_new["RESIDENCE_SGG_CD"] = pd.to_numeric(df_new["RESIDENCE_SGG_CD"], errors="coerce")
    X = pre.transform(df_new)
    cluster_id = int(km.predict(X)[0])
    dists = km.transform(X)[0].round(3).tolist()
    return cluster_id, dists

if submitted:
    new_user = {
        "AGE_GRP": age_grp,
        **styles,
        "TRAVEL_STATUS_ACCOMPANY": accompany,
        "RESIDENCE_SGG_CD": res_code,
    }
    cid, dists = predict_cluster(preprocessor, kmeans, new_user)
    recs = recommendation_profile.get(cid, ["ì¶”ì²œ ë°ì´í„° ë¶€ì¡±"])

    st.success("ì¶”ì²œ ì™„ë£Œ!")
    T("### â­ ë‹¹ì‹ ì„ ìœ„í•œ ë§ì¶¤ ì—¬í–‰ì§€ â­")
    T(f"**{CLUSTER_DESC.get(cid, 'êµ°ì§‘ ì„¤ëª… ì—†ìŒ')}**")
    st.divider()
    T("#### ì¶”ì²œ ì—¬í–‰ì§€")
    for p in recs:
        T(f"- {p}")

    with st.expander("ë””ë²„ê·¸ ë³´ê¸° (ì…ë ¥/í´ëŸ¬ìŠ¤í„° ê±°ë¦¬)"):
        st.write("ì…ë ¥ íŠ¹ì§•:", new_user)
        st.write("í´ëŸ¬ìŠ¤í„° ê±°ë¦¬(ì‘ì„ìˆ˜ë¡ ê°€ê¹Œì›€):", {f"cluster_{i}":v for i,v in enumerate(dists)})